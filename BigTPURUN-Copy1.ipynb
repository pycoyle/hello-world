{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xs6XZAf7wmKe"
   },
   "source": [
    "# Instructions to reproduce the results on GCP\n",
    "\n",
    "### GPU:\n",
    "\n",
    "- Go to [AI platform notebooks](https://cloud.google.com/ai-platform-notebooks/)\n",
    "- Press \"Go to console\". If you don't see \"Go to console\" you need to create\n",
    "  a GCP account for free:\n",
    "    -  Press \"Get started for free\" and create an account.\n",
    "    - Open [AI platform notebooks](https://cloud.google.com/ai-platform-notebooks/)\n",
    "    - Press \"Go to console\"\n",
    "    - Press \"Enable API\"\n",
    "    - Wait for the previous step to finish and press \"GO TO INSTANCES PAGE\"\n",
    "- Press \"New Insance\" at the top -> \"Customize instance\".\n",
    "- Create a new instance with the following specifications:\n",
    "    - Region: **us-central1**\n",
    "    - Zone: **us-central1-b** (this is important for TPU)\n",
    "    - Environment: TensorFlow 2.1 Enterprise\n",
    "    - Machine type: `n1-highcpu-96` (96 vCPUs, 86.4 GB RAM)\n",
    "    - GPU Type: NVIDIA TESLA v100 GPU\n",
    "    - Tick \"install NVIDIA GPU driver\"\n",
    "    - Press create\n",
    "    - Press JUPYTERLAB and upload this notebook\n",
    "\n",
    "\n",
    "### TPU:\n",
    "- Follow the steps from from above but the GPU set up may be omitted\n",
    "- Go to [Compute Engine -> TPUs](https://pantheon.corp.google.com/compute/tpus)\n",
    "- Follow the hints to create a TPU node with the following specs:\n",
    "     -  Zone: **us-central1-b**\n",
    "     - TPU type: `v2-8` (you can use `v3-8` for better performance)\n",
    "     - TPU software version: `nightly`\n",
    "     - Press \"create\"\n",
    "- Wait for the node to start up. Take a note of the internal IP (something like `10.245.84.146`)\n",
    "- Open the JUPYTERLAB created by the steps above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfMDV86aLmJJ"
   },
   "source": [
    "# Notes\n",
    "\n",
    "In this colab we perform CVA-like calculation for a batch of vanilla interest \n",
    "rate swaps. We assume an underlying Hull-White model for a short rate.\n",
    "We propagate the rate for 136 steps and price 1 million swaps at each iteration.\n",
    "The swaps have tenures of up to 30 years with payment frequencies varying from\n",
    "1 to 12 months. \n",
    "\n",
    "The whole procedure takes **3 seconds** on a **TPU**. This is currently done in a single precision but should be shortly be available in double precision too. \n",
    "\n",
    "We compare sampling speed against CPU and GPU and provide a reference to QuantLib sampling speed.\n",
    "\n",
    "\n",
    "# Hull White future yield curves.\n",
    "\n",
    "For the single factor Hull white model, the conditional forward bond prices are of the [affine form](https://en.wikipedia.org/wiki/Hull%E2%80%93White_model#Bond_pricing_using_the_Hull%E2%80%93White_model):\n",
    "\n",
    "$$P(S, T) = A(S, T) e^{-B(S,T) r(S)}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$B(S, T) = \\frac{1}{\\alpha} \\left(1 - e^{-\\alpha (T-S) } \\right)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\ln A(S, T) &=& \\ln \\frac{P(0, T)}{P(0, S)} + B(S, T) f(0, S) - \\frac{\\sigma^2}{4\\alpha^3}\\left[1-e^{-\\alpha (T-S)}\\right]^2 (1-e^{-2\\alpha S}) \\\\\n",
    "&=& \\ln \\frac{P(0, T)}{P(0, S)} + B(S, T) f(0, S) - \\frac{\\sigma^2}{4\\alpha}B(S,T)^2 (1-e^{-2\\alpha S})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "and\n",
    "$$f(0, S) = -\\frac{\\partial}{\\partial S} \\ln P(0, S)$$\n",
    "\n",
    "Assuming we are given the pair $(S, r(S))$, we can use the above to compute the discount factors as \"observed\" at time $S$. The set of future times will be given to us and the $r$ at those times will be computed by sampling (see next section.).t those times will be computed by sampling (see next section.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yl_1VMj-Y4vI"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import time\n",
    "!pip install --upgrade tf_quant_finance -q\n",
    "# Disable eager execution since TPU routines are better handled in graph mode\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import tf_quant_finance as tff\n",
    "\n",
    "# Load TFF dates library\n",
    "dates = tff.experimental.dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9Bi7uvGZTe4"
   },
   "outputs": [],
   "source": [
    "#@title Global dtype. TPU will soon support FP64\n",
    "dtype = np.float32 #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "jUfY_a1et1h8"
   },
   "outputs": [],
   "source": [
    "#@title TFF Fixing funtion and VanillaSwap class\n",
    "\n",
    "def get_fixings(*, dates_tensor, discount_fn, day_count, dtype):\n",
    "  \"\"\"Computes fixings implied by the input dates tensor and a discounting curve.\n",
    "\n",
    "  Given dates `[d1, d2, .. , dn]` computes forward rates `fwd_rates` between\n",
    "  `[d_i, d_{i+1}]` for `i=0,..., n-1` and returns the corresponding deposit\n",
    "  rates defined as `1 + deposit_rates * day_count(d_i, d_{i+1}) = fwd_rates`.\n",
    "\n",
    "  Args:\n",
    "    dates_tensor: `DateTensor` of shape `[num_dates, batch_shape]`.\n",
    "    discount_fn: A callable that maps `DateTensor` to a real number of `dtype`\n",
    "      which corresponds to discounting.\n",
    "    day_count: A daycounting function.\n",
    "    dtype: Output `dtype`.\n",
    "  \n",
    "  Returns:\n",
    "    A `Tensor` of the specified `dtype` and of shape\n",
    "    `[num_dates - 1, batch_shape]` that correponds to the deposit rates at\n",
    "    `dates_tensor[1:]`.\n",
    "  \"\"\" \n",
    "  start_dates = dates_tensor[:-1]\n",
    "  end_dates = dates_tensor[1:]\n",
    "  disc_start = discount_fn(start_dates)\n",
    "  disc_end = discount_fn(end_dates)\n",
    "  t = day_count(start_date=start_dates, end_date=end_dates, dtype=dtype)\n",
    "  if t.shape.as_list() != disc_end.shape.as_list():\n",
    "    t = tf.expand_dims(t, axis=-1)\n",
    "  fixings = tf.where(t > 1e-8,\n",
    "                     (disc_start/disc_end - 1.0) / t,\n",
    "                     0.0)\n",
    "  fixings = tf.where(t > 0, fixings, 0.0)\n",
    "  return fixings\n",
    "\n",
    "class VanillaSwap:\n",
    "  \"\"\"Simple interest rate swap.\"\"\"\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               calc_date,\n",
    "               fixed_leg_dates,\n",
    "               float_leg_dates,\n",
    "               fixed_leg_rates,\n",
    "               float_leg_rates,\n",
    "               notional,\n",
    "               day_count,\n",
    "               discount_fn,\n",
    "               dtype=None):\n",
    "    \"\"\"Initializer.\n",
    "    \n",
    "    Args:\n",
    "      calc_date: An instance of `DateTensor` of zero shape. The reference date\n",
    "        to which perform the discounting.\n",
    "      fixed_leg_dates: A `DateTensor` of shape `[batch_shape, n]` representing\n",
    "        the cashflow dates of the fixed leg including the `calc_date` as the\n",
    "        first entry for each swap in the batch.\n",
    "      float_leg_dates: A `DateTensor` of shape `[batch_shape, n]` representing\n",
    "        the cashflow dates of the float leg including the `calc_date` as the\n",
    "        first entry for each swap in the batch. \n",
    "      fixed_leg_rates: A real `Tensor` of shape brodcastable with\n",
    "        `[batch_shape, n]` representing the fixed rates of the swap.\n",
    "      float_leg_rates: A real `Tensor` of shape brodcastable with\n",
    "        `[batch_shape, n]` and of the same dtype as `fixed_leg_rates`.\n",
    "        Represents the float rates of the swap.\n",
    "      notional: A real `Tensor` of shape brodcastable with `[batch_shape, n]`\n",
    "        and of the same dtype as `fixed_leg_rates`. Represents the notional of\n",
    "        the swap.\n",
    "      day_count: A daycount convention. One of `dates.daycounts`.\n",
    "      discount_fn: A callable that maps `DateTensor` to a real number of the\n",
    "        same `dtype` as `fixed_leg_rates` which corresponds to the discounting\n",
    "        function.\n",
    "      dtype: A `dtype` for the underlying real `Tensor`s.\n",
    "        Default value: None which maps to the `dtype` inferred by TensorFlow.\n",
    "    \"\"\"  \n",
    "    self._calc_date = calc_date\n",
    "    self._fixed_leg_dates= fixed_leg_dates\n",
    "    self._float_leg_dates = float_leg_dates\n",
    "    self._fixed_leg_rates = fixed_leg_rates\n",
    "    self._float_leg_rates = float_leg_rates\n",
    "    self._notional = notional\n",
    "    self._day_count = day_count\n",
    "    self._discount_fn = discount_fn\n",
    "    self._dtype = dtype\n",
    "\n",
    "  def fixed_cashflows(self):\n",
    "    \"\"\"Returns all fixed cashflows at `fixed_leg_dates`.\"\"\"\n",
    "    start_dates = self._fixed_leg_dates[:-1]\n",
    "    end_dates = self._fixed_leg_dates[1:]\n",
    "    t = self._day_count(\n",
    "        start_date=start_dates, end_date=end_dates, dtype=self._dtype)\n",
    "    t = tf.where(t > 0, t, 0)\n",
    "    if t.shape.as_list() != self._float_leg_rates.shape.as_list():\n",
    "      t = tf.expand_dims(t, axis=-1)\n",
    "    return self._notional * self._fixed_leg_rates * t\n",
    "\n",
    "  def float_cashflows(self):\n",
    "    \"\"\"Returns all float cashflows at `float_leg_dates`.\"\"\"\n",
    "    start_dates = self._float_leg_dates[:-1]\n",
    "    end_dates = self._float_leg_dates[1:]\n",
    "    t = self._day_count(\n",
    "        start_date=start_dates, end_date=end_dates, dtype=self._dtype)\n",
    "    t = tf.where(t > 0, t, 0)\n",
    "    if t.shape.as_list() != self._float_leg_rates.shape.as_list():\n",
    "      t = tf.expand_dims(t, axis=-1)\n",
    "    return self._notional * self._float_leg_rates * t\n",
    "\n",
    "  def float_leg_present_value(self):\n",
    "    \"\"\"Returns the value of the float leg discounted to `self.calc_date`.\"\"\"\n",
    "    payment_dates = self._float_leg_dates[1:]\n",
    "    cashflows = self.float_cashflows()\n",
    "    return tf.reduce_sum(cashflows * self._discount_fn(payment_dates),\n",
    "                         axis=0)\n",
    "\n",
    "  def fixed_leg_present_value(self):\n",
    "    \"\"\"Returns the value of the fixed leg discounted to `self.calc_date`.\"\"\"\n",
    "    payment_dates = self._fixed_leg_dates[1:]\n",
    "    cashflows = self.fixed_cashflows()\n",
    "    return tf.reduce_sum(cashflows * self._discount_fn(payment_dates),\n",
    "                         axis=0)\n",
    "\n",
    "  def price(self):\n",
    "    \"\"\"Returns the value of the swap discounted to `self.calc_date`.\"\"\"\n",
    "    return self.float_leg_present_value() - self.fixed_leg_present_value()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "YCPKrVeq9M8p"
   },
   "outputs": [],
   "source": [
    "#@title Swap schedule generation and Hull-White model parameters\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "YieldParams = namedtuple('YieldParams', ['a0', 'a1', 'a2'])\n",
    "\n",
    "def random_yield_params(size, max_time=30.0):\n",
    "  r0 = dtype(np.random.rand(size)* (0.07 - 0.005) + 0.005)\n",
    "  rT = dtype(np.random.rand(size)* (0.07 - 0.005) + 0.005)\n",
    "  r_mins = np.minimum(r0, rT)\n",
    "  r_maxs = np.maximum(r0, rT)\n",
    "  do_low = np.random.rand(size) > dtype(0.5)\n",
    "  a0 = np.random.rand(size)\n",
    "  a0 = np.where(do_low, a0 * (r_mins - 0.0001) + 0.0001, a0 * (0.08 - r_maxs) + r_maxs)\n",
    "  a2 = max_time / (1 + np.random.choice([-1.0, 1.0], size=size) * np.sqrt((rT - a0)/(r0-a0)))\n",
    "  a1 = (r0 - a0) / a2 / a2\n",
    "  return YieldParams(a0=a0,a1=a1,a2=a2)\n",
    "\n",
    "def log_current_discount_fwd_fn(yield_params):\n",
    "  \"\"\"Suitable for the next log discount evaluator below.\"\"\"\n",
    "  a0 = np.array(yield_params.a0, dtype=dtype)\n",
    "  a1 = np.array(yield_params.a1, dtype=dtype)\n",
    "  a2 = np.array(yield_params.a2, dtype=dtype)\n",
    "  def eval_fn(times):\n",
    "    \"\"\"Gives the log zero coupon bond price and the instantaneous forward rate.\"\"\"\n",
    "    return -(a0 + a1 * (times - a2)**2) * times, (a0 - a1 * a2 * a2 / 3) + 3 * a1 * (times - 2 * a2 / 3) ** 2\n",
    "  return eval_fn\n",
    "\n",
    "\n",
    "HullWhiteData = namedtuple('HullWhiteData',\n",
    "                           ['mean_reversion', 'volatility',\n",
    "                            'log_discount_fwd_fn'])\n",
    "\n",
    "\n",
    "def gen_hull_white_params():\n",
    "  mean_reversion = np.random.rand() * 0.1\n",
    "  volatility = np.random.rand() * 0.3\n",
    "  present_yield_curve_params = random_yield_params(1)\n",
    "  return HullWhiteData(\n",
    "      mean_reversion=mean_reversion,\n",
    "      volatility=volatility,\n",
    "      log_discount_fwd_fn=log_current_discount_fwd_fn(present_yield_curve_params))\n",
    "  \n",
    "def generate_short_rates(initial_short_rates,\n",
    "                         hull_white_params, times, num_scenarios,\n",
    "                         dtype):\n",
    "  a = dtype(hull_white_params.mean_reversion)\n",
    "  sigma = dtype(hull_white_params.volatility)\n",
    "  def instant_forward_rate_fn(t):\n",
    "    return hull_white_params.log_discount_fwd_fn(t)[1]\n",
    "  process = tff.models.hull_white.HullWhiteModel1F(\n",
    "      mean_reversion=a, volatility=sigma,\n",
    "      instant_forward_rate_fn=instant_forward_rate_fn,\n",
    "      dtype=dtype)\n",
    "  sample_paths = process.sample_paths\n",
    "  paths = sample_paths(\n",
    "      times,\n",
    "      num_samples=num_scenarios,\n",
    "      initial_state=initial_short_rates,\n",
    "      seed=42)\n",
    "  paths = tf.squeeze(paths, axis=-1)\n",
    "  # Shape [num_times, num_samples]\n",
    "  return tf.transpose(paths)\n",
    "\n",
    "def discount_curve_at_times(\n",
    "    calc_date,\n",
    "    short_rates,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    current_disc_fwd_fn,\n",
    "    day_count,\n",
    "    mean_revs,\n",
    "    sigmas):\n",
    "  \"\"\"Computes forward discount factors.\n",
    "\n",
    "  Produces P(S, T) i.e. the discount factor as seen at time 'S' the calculation date\n",
    "  for expiry at time 'T' the evaluation date.\n",
    "\n",
    "  Time today is 0. The eval times are allowed to be negative but not the calc times\n",
    "\n",
    "  Args:\n",
    "    calc_date: current date.\n",
    "    short_rates: The short rates of shape: [N_scenarios].\n",
    "    start_date: The calculation time.\n",
    "    end_date: The evaluation dates.\n",
    "    currency_disc_fwd_fn: A callable that returns instantaneous forward rate and\n",
    "      the log-discount at the specified times. \n",
    "    mean_revs: A tensor of shape [num_currencies] The mean reversions for\n",
    "      the HW model.\n",
    "    sigmas: A tensor of same shape as mean_revs.\n",
    "  \n",
    "  Returns: A tensor of shape [end_date.shape] + [N_scenarios]\n",
    "  \"\"\"\n",
    "  # S- T\n",
    "  day_fractions = day_count(\n",
    "      start_date=start_date,\n",
    "      end_date=end_date, dtype=dtype)\n",
    "  S = day_count(\n",
    "      start_date=calc_date,\n",
    "      end_date=start_date, dtype=dtype)\n",
    "  T = day_count(\n",
    "      start_date=calc_date,\n",
    "      end_date=end_date, dtype=dtype)\n",
    "\n",
    "  b_exp = mean_revs * day_fractions  # shape [N_calc_dates, n_eval_dates]\n",
    "  b = (1 - tf.exp(-b_exp)) / mean_revs\n",
    "  lnP_p = current_disc_fwd_fn(T)[0]  # shape [n_eval_dates]\n",
    "  lnP_den, inst_fwd = current_disc_fwd_fn(S)  # output of shapes [n_calc_dates, n_eval_dates]\n",
    "  lnA = (lnP_p - lnP_den + b * inst_fwd\n",
    "         - ((sigmas * b) ** 2) * (1 - tf.exp(-2 * mean_revs * S)))\n",
    "  lnA = tf.expand_dims(lnA, axis=-1)\n",
    "  b = tf.expand_dims(b, axis=-1)\n",
    "  short_rates = tf.expand_dims(short_rates, axis=0)\n",
    "  discounts = tf.exp(lnA - b * short_rates)\n",
    "  # Adjust for when calc_date > eval_date\n",
    "  return tf.where(tf.expand_dims(T > S, -1), discounts, 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpul0dPeODAs"
   },
   "source": [
    "# Pricing vaniall swaps comparison. CPU vs GPU vs TPU\n",
    "\n",
    "Note that **QuantLib** pricing speed for a swap with 40 payments:\n",
    "**10000 swaps / sec** on a Intel . TPU can price **2 million / sec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igjBC5XKtuXY"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "hull_white_params = gen_hull_white_params()\n",
    "calc_date = dates.from_year_month_day(2015, 9, 9)\n",
    "# Corresponding ql.WeekendsOnly calendar\n",
    "calendar = dates.HolidayCalendar2(\n",
    "    weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY)\n",
    "# Business day convention\n",
    "bussiness_convention = dates.BusinessDayConvention.FOLLOWING\n",
    "day_count = dates.daycounts.actual_360\n",
    "settlement_days = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqxmA8JC47Y5"
   },
   "outputs": [],
   "source": [
    "# Generate swaps\n",
    "TENORS = [1, 3, 6, 12] # months\n",
    "\n",
    "NUM_SWAPS = 100 #@param\n",
    "NUM_CALCULATION_DATES = 136 #@param\n",
    "\n",
    "NUM_SWAPS_PER_TENOR = NUM_SWAPS // len(TENORS)\n",
    "# Start date of the swaps\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "schedule_dates = []\n",
    "long_short = []\n",
    "\n",
    "for t in TENORS:\n",
    "  random_shift = np.int32(t * 2 *\n",
    "                          (np.random.rand(NUM_SWAPS_PER_TENOR) - 0.5) * 30)\n",
    "  start_date = calendar.add_business_days(\n",
    "      calc_date, random_shift, roll_convention=bussiness_convention)\n",
    "  # Maximum swap tenure is 30 years\n",
    "  swap_tenure = 1 + np.int32(30 * (np.random.rand(NUM_SWAPS_PER_TENOR)))\n",
    "  period = dates.periods.PeriodTensor(swap_tenure, dates.PeriodType.YEAR)\n",
    "  end_date = calendar.add_period_and_roll(start_date, period,\n",
    "                                          bussiness_convention)\n",
    "  # Exchange schedules\n",
    "  schedule = dates.PeriodicSchedule(\n",
    "      start_date=start_date, end_date=end_date,\n",
    "      tenor=dates.periods.months(t),\n",
    "      holiday_calendar=calendar,\n",
    "      roll_convention=bussiness_convention)\n",
    "  schedule_date = schedule.dates()\n",
    "  # Record swap data\n",
    "  start_dates.append(start_date)\n",
    "  end_dates.append(end_date)\n",
    "  schedule_dates.append(schedule_date.transpose())\n",
    "  long_short.append(2 * (np.random.binomial(1, 0.52, size=random_shift.shape) - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2A8HblZS6-w_"
   },
   "outputs": [],
   "source": [
    "def discount_curve(dates):\n",
    "  day_fractions = day_count(\n",
    "      start_date=calc_date,\n",
    "      end_date=dates)\n",
    "  def discount_curve(t):\n",
    "    return tf.exp(hull_white_params.log_discount_fwd_fn(t)[0])\n",
    "  discounts = discount_curve(day_fractions)\n",
    "  return tf.where(dates > calc_date, discounts, 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKaWfyiaVN7H"
   },
   "outputs": [],
   "source": [
    "swaps = []\n",
    "\n",
    "for schedule in schedule_dates:\n",
    "  # Compute the float let rates\n",
    "  float_leg_rates = get_fixings(\n",
    "          dates_tensor=schedule,\n",
    "          day_count=day_count,\n",
    "          discount_fn=discount_curve,\n",
    "          dtype=dtype)\n",
    "\n",
    "  swap = VanillaSwap(\n",
    "      calc_date=calc_date,\n",
    "      fixed_leg_dates=schedule,\n",
    "      float_leg_dates=schedule,\n",
    "      fixed_leg_rates=0.0039,\n",
    "      float_leg_rates=float_leg_rates,\n",
    "      notional=1000000,\n",
    "      day_count=day_count,\n",
    "      discount_fn=discount_curve,\n",
    "      dtype=dtype)\n",
    "  swaps.append(swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzgbqgotYsyA"
   },
   "outputs": [],
   "source": [
    "def swap_price():\n",
    "  return [position * swap.price()\n",
    "          for swap, position in zip(swaps, long_short)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZeqy0dnN6Nq"
   },
   "source": [
    "### Speed comparison accross platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1z6911bZd8M"
   },
   "outputs": [],
   "source": [
    "tpu_price = tf.compat.v1.tpu.rewrite(swap_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INtS6gw2ZsG8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x03\\x02\\x02\\x02\\x10\\x01\\x18\\x08\"\\x18\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x01\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x01\\x01\\x00\\x01\\x01\\x01'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare session (resolves cluster settings)\n",
    "internal_ip = \"10.141.97.250\"\n",
    "sess = tf.compat.v1.Session(\"grpc://{}:8470\".format(internal_ip))\n",
    "sess.run(tf.compat.v1.tpu.initialize_system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLaHzypeZzQP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.45 ms ± 380 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "#@title TPU pricing speed\n",
    "# This is for a single core. Note that TPU has 8 cores.\n",
    "sess.run(tpu_price) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5FaXBzDN1Yd"
   },
   "outputs": [],
   "source": [
    "#with tf.device(\"/CPU:0\"):\n",
    "#  cpu_price = tf.xla.experimental.compile(swap_price)\n",
    "#  cpu_price2 = xla.compile(swap_price)\n",
    "\n",
    "#sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "colab_type": "code",
    "id": "1TABM859hYz-",
    "outputId": "3fc34bb3-0a42-4790-8da3-5db3933b4ca5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cpu_price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4679b9610623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'#@title CPU pricing speed (112 virtual CPUs, see below)\\nsess.run(cpu_price) \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cpu_price' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#@title CPU pricing speed (112 virtual CPUs, see below)\n",
    "sess.run(cpu_price) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbVkpRDLe86V"
   },
   "outputs": [],
   "source": [
    "#@title Tesla V100 GPU pricing speed\n",
    "with tf.device(\"/gpu:0\"):\n",
    "  gpu_price = tf.xla.experimental.compile(swap_price)\n",
    "sess = tf.compat.v1.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwJl_70Fe__n"
   },
   "outputs": [],
   "source": [
    "#@title TPU pricing speed\n",
    "#%%timeit\n",
    "#sess.run(gpu_price) #  4.11 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pz3_zhvFKeWy"
   },
   "source": [
    "## CPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhJmmvenKcHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 2\n",
      "initial apicid\t: 2\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 2\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 3\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2300.000\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 4\n",
      "core id\t\t: 1\n",
      "cpu cores\t: 2\n",
      "apicid\t\t: 3\n",
      "initial apicid\t: 3\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp kaiser fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
      "bogomips\t: 4600.00\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbAk9wLPt3QY"
   },
   "source": [
    "# Sample 1 scenario for 1 million swaps at 136 time points on a TPU\n",
    "\n",
    "A standard TPU with 8 cores can solve this problem in **3 seconds**.\n",
    "\n",
    "Note that similarly, one can get access to a TPU with **512 cores**, in which case\n",
    "the scenarios can be generated at a speed of **45 ms**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWHkVud_t5Yr"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "calc_date = dates.from_year_month_day(2015, 9, 9)\n",
    "# Corresponding ql.WeekendsOnly calendar\n",
    "calendar = dates.HolidayCalendar2(\n",
    "    weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY)\n",
    "# Business day convention\n",
    "bussiness_convention = dates.BusinessDayConvention.FOLLOWING\n",
    "day_count = dates.daycounts.actual_360\n",
    "settlement_days = 2\n",
    "\n",
    "TENORS = [1, 3, 6, 12] # months\n",
    "\n",
    "NUM_SWAPS = 1000 #@param\n",
    "NUM_CALCULATION_DATES = 136 #@param\n",
    "NUM_SAMPLES =  100000 #@param\n",
    "NUM_TPU_CORES = 8 #@param\n",
    "\n",
    "NUM_SWAPS_PER_TENOR = NUM_SWAPS // len(TENORS)\n",
    "\n",
    "def generate_swap_schedules(num_swaps_per_tenor):\n",
    "  # Start date of the swaps\n",
    "  start_dates = []\n",
    "  end_dates = []\n",
    "  schedule_dates = []\n",
    "  long_short = []\n",
    "\n",
    "  for t in TENORS:\n",
    "    random_shift = np.int32(t * 2 *\n",
    "                            (np.random.rand(num_swaps_per_tenor) - 0.5) * 30)\n",
    "    start_date = calendar.add_business_days(\n",
    "        calc_date, random_shift, roll_convention=bussiness_convention)\n",
    "    # Maximum swap tenure is 30 years\n",
    "    swap_tenure = 1 + np.int32(30 * (np.random.rand(num_swaps_per_tenor)))\n",
    "    period = dates.periods.PeriodTensor(swap_tenure, dates.PeriodType.YEAR)\n",
    "    end_date = calendar.add_period_and_roll(start_date, period,\n",
    "                                            bussiness_convention)\n",
    "    # Exchange schedules\n",
    "    schedule = dates.PeriodicSchedule(\n",
    "        start_date=start_date, end_date=end_date,\n",
    "        tenor=dates.periods.months(t),\n",
    "        holiday_calendar=calendar,\n",
    "        roll_convention=bussiness_convention)\n",
    "    schedule_date = schedule.dates()\n",
    "    # Record swap data\n",
    "    start_dates.append(start_date)\n",
    "    end_dates.append(end_date)\n",
    "    schedule_dates.append(schedule_date.transpose())\n",
    "    long_short.append(2 * (np.random.binomial(1, 0.501, size=random_shift.shape) - 0.5))\n",
    "  return schedule_dates, long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5TFz5u3yXrq"
   },
   "outputs": [],
   "source": [
    "\n",
    "schedule_dates = []\n",
    "long_short = []\n",
    "\n",
    "# We split swaps into 8 date tensors in order to distribute the computations\n",
    "for _ in range(NUM_TPU_CORES):\n",
    "  schedules, positions = generate_swap_schedules(\n",
    "      NUM_SWAPS_PER_TENOR // NUM_TPU_CORES)\n",
    "  schedule_dates.append(schedules)\n",
    "  long_short.append(positions)\n",
    "\n",
    "# All the calculations date at which to price the swaps\n",
    "calc_times = calendar.add_business_days(calc_date, range(NUM_CALCULATION_DATES),\n",
    "                                        roll_convention=bussiness_convention)\n",
    "hull_white_params = gen_hull_white_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVcIG5azmn1p"
   },
   "outputs": [],
   "source": [
    "# Since storing 1 million swaps take a lot of memory, we \n",
    "# compute aggragated values for each date, i.e.,\n",
    "# max(sum(swap_prices_at_date_i), 0)\n",
    "def aggregated_prices_for_schedule(schedule_dates, long_short):\n",
    "  def aggregated_prices_at_time(iter_num, short_rates):\n",
    "    def discount_curve(dates):\n",
    "      return discount_curve_at_times(\n",
    "          calc_date,\n",
    "          short_rates,\n",
    "          calc_times[iter_num],\n",
    "          dates,\n",
    "          hull_white_params.log_discount_fwd_fn,\n",
    "          day_count,\n",
    "          hull_white_params.mean_reversion,\n",
    "          hull_white_params.volatility)\n",
    "    swaps = []\n",
    "    for schedule in schedule_dates:\n",
    "      # Compute the float let rates\n",
    "      float_leg_rates = get_fixings(\n",
    "              dates_tensor=schedule,\n",
    "              day_count=day_count,\n",
    "              discount_fn=discount_curve,\n",
    "              dtype=dtype)\n",
    "\n",
    "      swap = VanillaSwap(\n",
    "          calc_date=calc_times[iter_num],\n",
    "          fixed_leg_dates=schedule,\n",
    "          float_leg_dates=schedule,\n",
    "          fixed_leg_rates=0.0039,\n",
    "          float_leg_rates=float_leg_rates,\n",
    "          notional=1000000,\n",
    "          day_count=day_count,\n",
    "          discount_fn=discount_curve,\n",
    "          dtype=dtype)\n",
    "      swaps.append(swap)\n",
    "    prices = [np.expand_dims(position, axis=-1) * swap.price()\n",
    "              for swap, position in zip(swaps, long_short)]\n",
    "    return tf.reduce_sum(prices, axis = 0)\n",
    "  return aggregated_prices_at_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEv6mR7Ju3hg"
   },
   "outputs": [],
   "source": [
    "# Distributed calculations on a TPU\n",
    "aggregated_prices = tf.TensorArray(dtype, size=NUM_CALCULATION_DATES)\n",
    "\n",
    "short_rates = generate_short_rates(\n",
    "    0.02, hull_white_params,\n",
    "    day_count(start_date=calc_date,\n",
    "              end_date=calc_times, dtype=dtype),\n",
    "    NUM_SAMPLES,\n",
    "    dtype)\n",
    "\n",
    "\n",
    "def cond_fn(iter_num, aggregated_prices):\n",
    "  return iter_num < NUM_CALCULATION_DATES \n",
    "\n",
    "def body_fn(iter_num, aggregated_prices):\n",
    "  all_replications = []\n",
    "  for i in range(NUM_TPU_CORES):\n",
    "    with tf.device(\"/job:tpu_worker/replica:0/task:0/device:TPU:{}\".format(i)):\n",
    "      all_replications.append(\n",
    "          tf.compat.v1.tpu.rewrite(\n",
    "              aggregated_prices_for_schedule(schedule_dates[i],\n",
    "                                            long_short[i]),\n",
    "          inputs=[iter_num, short_rates[iter_num]]))\n",
    "  aggregated_replicas = 0\n",
    "  for replica in all_replications:\n",
    "    aggregated_replicas += replica[0]\n",
    "  aggregated_replicas =tf.reduce_sum(aggregated_replicas, axis=0)\n",
    "  aggregated_replicas = tf.maximum(aggregated_replicas, 0)\n",
    "  aggregated_replicas = tf.reduce_mean(aggregated_replicas)\n",
    "  aggregated_prices = aggregated_prices.write(iter_num, aggregated_replicas)\n",
    "  return iter_num + 1, aggregated_prices\n",
    "\n",
    "_, aggregated_prices = tf.while_loop(cond_fn, body_fn, (0, aggregated_prices))\n",
    "\n",
    "summary = aggregated_prices.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWNFPnjoy7r9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x03\\x02\\x02\\x02\\x10\\x01\\x18\\x08\"\\x18\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\x01\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x01\\x01\\x00\\x01\\x01\\x01'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare session (resolves cluster settings)\n",
    "internal_ip = \"10.141.97.250\"\n",
    "sess = tf.compat.v1.Session(\"grpc://{}:8470\".format(internal_ip))\n",
    "sess.run(tf.compat.v1.tpu.initialize_system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cxxW75ly83p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall time:  144.42943406105042\n"
     ]
    }
   ],
   "source": [
    "#@title TPU performance (after automatic optimizations)\n",
    "t = time.time()\n",
    "res_tpu = sess.run(summary)\n",
    "print(\"wall time: \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Qpul0dPeODAs",
    "pz3_zhvFKeWy"
   ],
   "name": "Swap_CVA_like_calculation_on_a_TPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
